#!/bin/bash
# -*- coding: utf-8 mode: sh -*- vim:sw=4:sts=4:et:ai:si:sta:fenc=utf-8
source /etc/nulib.sh || exit 1
source /g/init.env || exit 1

APPDIR=/app/dremgr
: "${APP_DATADIR:=/data/dre}"
: "${DLDIR:=$APP_DATADIR/downloads}"
: "${AODIR:=$APP_DATADIR/addons}"
: "${DOCDIR:=$APP_DATADIR/documentation}"
: "${WORKDIR:=$APP_DATADIR/tmp.$$}"
export PGDATABASE="$DBNAME" PGUSER="$POSTGRES_USER"
unset PGHOST PGPORT

read -a VxxFIX_FC <<<"${VxxFIX_FC//
/ }"

function recoverable_curl_error() {
    case "$1" in
    5|6|7|22) return 0;;
    *) return 1;;
    esac
}
DL_MAX=5
function dl() {
    local r=22 count=0
    while recoverable_curl_error $r; do
        curl -fsSO -u "$DRE_USER:$DRE_PASSWORD" "$DRE_URL/$1"; r=$?
        if recoverable_curl_error $r; then
            let count=count+1
            [ $count -gt $DL_MAX ] && break
            sleep 30
            qstep "nouvelle tentative $count/$DL_MAX..."
        fi
    done
    return $r
}

export RUNSQL_IGNORE_ERRORS=1
RUNSQL_ARGS=()
function runsql_ignore_errors() {
    if [ -n "$1" ]; then
        RUNSQL_IGNORE_ERRORS=1
        RUNSQL_ARGS=()
    else
        RUNSQL_IGNORE_ERRORS=
        RUNSQL_ARGS=(-v ON_ERROR_STOP=1)
    fi
}
function runsql() {
    quietc psql "${RUNSQL_ARGS[@]}" -c "$@"
}
RUNFILE_PREFIX=()
function _runfile() {
    if [[ "$file" == *.sql ]]; then
        qstep "psql $file"
        if ! quietc "${RUNFILE_PREFIX[@]}" psql "${RUNSQL_ARGS[@]}" -f "$file"; then
            [ -z "$RUNSQL_IGNORE_ERRORS" ] && return 1
        fi
    elif [ -x "$file" ]; then
        qstep "exec $file"
        if ! quietc "${RUNFILE_PREFIX[@]}" "./$file"; then
            [ -z "$RUNSQL_IGNORE_ERRORS" ] && return 1
        fi
    else
        qstep "ignore $file"
    fi
}
function runfile() {
    local cwd dir file r
    setx dir=dirname -- "$1"
    setx file=basename -- "$1"
    setx cwd=pwd
    cd "$dir"
    _runfile; r=$?
    cd "$cwd"
    return $r
}
function rundir() {
    local -a files; local cwd file r
    setx cwd=pwd
    cd "$1"
    setx -a files=ls_files .
    for file in "${files[@]}"; do
        if [[ "$file" == *.sql ]]; then
            _runfile; r=$?
        elif [ -x "$file" ]; then
            _runfile; r=$?
        else
            r=0
        fi
        [ $r -eq 0 ] || break
    done
    cd "$cwd"
    return $r
}

declare -A ALL_FILES
DL_FILES=()
DROP_SCHEMA_SCHEMAS=()
IMPORT_SCHEMA_SCHEMAS=()
DROP_MONGO_SCHEMAS=()
IMPORT_MONGO_SCHEMAS=()
IMPORT_MONGO_COLLECTIONS=()
function add2all_files() {
    local file="$2"
    ALL_FILES["$file"]=1
}
function _add_bin() {
    local file="$1" schema="$1"
    schema="${schema%.bin}"
    schema="${schema##*-$Timestamp-}"
    DROP_SCHEMA_SCHEMAS+=("schema_$schema")
    IMPORT_SCHEMA_SCHEMAS+=("$schema")
    _add_file=1
}
function _add_json() {
    local file="$1" schema="$1"
    schema="${schema%.gz}"
    schema="${schema%.json}"
    schema="${schema##*-$Timestamp-}"
    collection="${schema#*-}"
    schema="${schema%%-*}"
    if ! array_contains IMPORT_MONGO_SCHEMAS "$schema"; then
        DROP_MONGO_SCHEMAS+=("mongo_$schema")
        IMPORT_MONGO_SCHEMAS+=("$schema")
    fi
    IMPORT_MONGO_COLLECTIONS+=("$schema:$collection")
    _add_file=1
}
function add2dl_files() {
    local sum="$1" file="$2"

    if [[ "$file" != "$DRE_PREFIX"* ]]; then
        quietc_echo "$file: KO ce fichier sera ignoré"
        return
    fi

    local _add_file
    if [[ "$file" == *.bin ]]; then
        _add_bin "$file"
    elif [[ "$file" == *.json ]]; then
        if [ -z "${ALL_FILES[$file.gz]:-}" ]; then
            # n'inclure le .json que si .json.gz n'existe pas déjà
            _add_json "$file"
        fi
    elif [[ "$file" == *.json.gz ]]; then
        _add_json "$file"
    else
        ewarn "$file: format non reconnu. le fichier sera ignoré"
    fi
    if [ -n "$_add_file" ]; then
        [ -f "$file" ] || quietc_echo "$file: OK ce fichier sera téléchargé"
        [ -n "$Tmpsums" ] && echo "$sum $(pwd)/$file" >>"$Tmpsums"
        DL_FILES+=("$file")
    fi
}

clean_import_log=
step_dl=
Timestamp=
ForceDlSums=
Clean=1
step_checkao=
Klone=
UpdateAo=1
MinimizeDowntime="$MINIMIZE_DOWNTIME"
step_import=
step_import_bin=
step_import_json=
step_runao=
SelectAo=
step_notifao=
args=(
    "télécharger les dumps"
    --clean-import-log clean_import_log=yes "++Forcer le vidage du fichier import.log avant de démarrer"
    --keep-import-log clean_import_log=no "++Interdire le vidage du fichier import.log avant de démarrer"
    --download step_dl=1 "++Télécharger les fichiers du jour"
    -@:,--timestamp Timestamp= "spécifier la date pour laquelle on fait le téléchagement, au format YYYYMMDD. implique --no-clean"
    -f,--force-dlsums ForceDlSums=1 "forcer le retéléchargement des checksums même si le fichier existe déjà"
    --clean Clean=1 "++Supprimer les fichiers de dumps obsolètes après un téléchargement réussi"
    -g,--no-clean Clean= "Ne pas nettoyer les fichiers de dumps à la fin du téléchargement"
    --checkao step_checkao=1 "++Vérifier les addons"
    --klone Klone=1 "++Refaire le clone des dépôts des addons au lieu de simplement les mettre à jour
(c'est parfois nécessaire parce que la mise à jour ne se fait pas correctement)"
    -e,--no-updateao UpdateAo= "++Ne pas mettre à jour les addons"
    --minimize-downtime MinimizeDowntime=1 "++Utiliser une base de données temporaire pour la mise à jour"
    --no-minimize-downtime MinimizeDowntime= "++Ne pas utiliser une base de données temporaire pour la mise à jour"
    --import step_import=1 "++Importer tous les dumps"
    --import-bin step_import_bin=1 "++Importer seulement les dumps .bin et le fichier DRE_VERSION"
    --import-json step_import_json=1 "++Importer seulement les dumps .json"
    --runao step_runao=1 "++Installer les addons, implique --checkao"
    -o:,--onlyao SelectAo= "++N'installer *que* l'addon spécifié"
    --notifao step_notifao=1 "++Exécuter les notifications à la fin de l'import"
)
parse_args "$@"; set -- "${args[@]}"

keep_import_log=1
[ -n "$step_import" ] && { step_import_bin=1; step_import_json=1; }
if [ -z "$step_dl" -a -z "$step_checkao" -a -z "$step_import_bin" -a -z "$step_import_json" -a -z "$step_runao" -a -z "$step_notifao" ]; then
    keep_import_log=
    step_dl=1
    step_checkao=1
    step_import_bin=1
    step_import_json=1
    step_runao=1
    step_notifao=1
fi
[ -n "$step_import_bin" -o -n "$step_import_json" ] && step_import=1
[ -n "$step_runao" ] && step_checkao=1

case "$clean_import_log" in
yes) keep_import_log=;;
no) keep_import_log=1;;
esac

setx DATE_DEB=date +"%F %T"; export DATE_DEB
export TEM_DOWNLOAD="$step_dl"
export TEM_IMPORT="$step_import"
export TEM_ADDONS="$step_runao"
export CRITICAL_ERROR=
export HAVE_ERRORS=
function critical() {
    CRITICAL_ERROR=1
    die "$@"
}
function at_exit() {
    [ -n "$step_notifao" ] || return 0
    etitle "Lancement des notifications"
    runsql_ignore_errors 1
    if [ -n "$NOTIF_TIMEOUT" ]; then
        RUNFILE_PREFIX=(timeout)
        if [ -n "$NOTIF_TIMEOUT_KILL" ]; then
            RUNFILE_PREFIX+=(-k "$NOTIF_TIMEOUT_KILL")
        fi
        RUNFILE_PREFIX+=("$NOTIF_TIMEOUT")
    fi
    for addon in "${ADDONS[@]}"; do
        if [[ "$addon" == *:* ]]; then
            aodir="${addon%:*}"
            vxx="${addon##*:}"
        else
            aodir="$addon"
            vxx=
        fi
        [ -d "$aodir/notifications" ] || continue

        etitle "$addon"; quietc_echo "** notifications $addon"
        rundir "$aodir/notifications"
        eend
    done
    eend
}
trap at_exit EXIT

quietc_logto ${keep_import_log:+-a} "$APP_DATADIR/import.log" "\
================================================================================"
qstep "Début de l'import le $DATE_DEB"

if [ -z "$DRE_PREFIX" ]; then
    DRE_PREFIX="${DRE_URL}"
    DRE_PREFIX="${DRE_PREFIX#https://dre-dump.}"
    DRE_PREFIX="${DRE_PREFIX%/*}"
    DRE_PREFIX="${DRE_PREFIX%.pc-scol.fr}"
    [ "$APP_PROFILE" == prod ] && DRE_PREFIX="prod-$DRE_PREFIX"
fi

cd "$DLDIR"
[ -n "$Timestamp" ] && Clean=
if [ "$Timestamp" == latest ]; then
    # prendre le dernier fichier checksums. utile pour --runao
    latest="$(ls checksums-* 2>/dev/null | tail -n1)"
    Timestamp="${latest#checksums-}"
    enote "Autosélection de -@ $Timestamp"
fi
if [ -z "$Timestamp" ]; then
    if [ -n "$V29FIX_DY" ]; then
        setx Timestamp=awk 'BEGIN { print strftime("%Y%m%d", mktime(strftime("%Y %m %d 00 00 00")) - 86400); }'
        enote "Sélection de -@ $Timestamp (v29fix_dy)"
    else
        setx Timestamp=date +%Y%m%d
    fi
fi
sums="checksums-$Timestamp"
version="DRE_VERSION_$Timestamp"

if [ -n "$step_dl" ]; then
    qinfo "Le préfixe des fichiers à télécharger est $DRE_PREFIX"

    if [ ! -f "$sums" -o -n "$ForceDlSums" ]; then
        qstep "dl $sums"
        dl "$sums" || critical
    fi
    ac_set_tmpfile Tmpsums
    eval "$(sed 's/^/add2all_files /' "$sums")"
    eval "$(sed 's/^/add2dl_files /' "$sums")"

    if [ ! -f "$version" ]; then
        qstep "dl $version"
        dl "$version" || critical
    fi
    for file in "${DL_FILES[@]}"; do
        if [ ! -f "$file" ]; then
            qstep "dl $file"
            dl "$file" || critical
        fi
    done

    qstep "Vérifications des sommes de contrôle"
    sha256sum --status -c "$Tmpsums" || critical

    if [ -n "$Clean" ]; then
        qstep "Nettoyage des fichiers obsolètes"
        age="${CRON_MAX_AGE:-30}"
        find -name "checksums-*" -mtime "+$age" -delete
        find -name "DRE_VERSION_*" -mtime "+$age" -delete
        find -name "$DRE_PREFIX-*" -mtime "+$age" -delete
    fi
elif [ -f "$sums" ]; then
    Tmpsums=
    eval "$(sed 's/^/add2all_files /' "$sums")"
    eval "$(sed 's/^/add2dl_files /' "$sums")"
else
    critical "Impossible de trouver le fichier $sums. Essayez avec l'option -@"
fi

estep "Calcul de la version"
eval "$(<"$version" sed -r 's/[{}]//g; s/,/\n/g' | sed -r 's/^"([a-z]+)":/\1=/')"

if [ -n "$step_checkao" ]; then
    estep "Vérification des addons"
    if [ -n "$SelectAo" -a "${SelectAo#dreaddon-}" == "$SelectAo" ]; then
        if [ ! -d "$AODIR/$SelectAo" -a -d "$AODIR/dreaddon-$SelectAo" ]; then
            SelectAo="dreaddon-$SelectAo"
        elif [ ! -d "$APPDIR/$SelectAo" -a -d "$APPDIR/dreaddon-$SelectAo" ]; then
            SelectAo="dreaddon-$SelectAo"
        fi
    fi

    read -a aourls <<<"${ADDON_URLS//
/ }"
    aonames=()
    for aourl in "${aourls[@]}"; do
        # ignorer lignes vides
        [ -n "$aourl" ] || continue
        # et commentaires
        [ "${aourl#\#}" == "$aourl" ] || continue

        # si pas d'url ni de chemin, rajouter le préfixe https://github.com/
        if [[ "$aourl" == *://* ]]; then : # url
        elif [ "${aourl#/}" != "$aourl" ]; then : # chemin absolu
        else aourl="https://github.com/$aourl"
        fi
        # récupérer la branche ou le commit
        if [[ "$aourl" == *#* ]]; then
            branch="${aourl##*#}"
            aourl="${aourl%#*}"
            commit=
        elif [[ "$aourl" == *^* ]]; then
            branch=
            commit="${aourl##*^}"
            aourl="${aourl%^*}"
        else
            branch=
            commit=
        fi

        setx aoname=basename "$aourl"
        aoname="${aoname%.git}"
        aodir="$AODIR/$aoname"

        if [ "$aoname" == dreaddon-local ]; then
            ewarn "le nom dreaddon-local est réservé. le dépôt $aourl a été ignoré"
            continue
        fi
        [ -z "$SelectAo" -o "$aoname" == "$SelectAo" ] || continue
        aonames+=("$aoname")

        if [ -n "$Klone" ]; then
            qstep "klean $aodir"
            rm -rf "$aodir"
        fi

        # ajouter le répertoire safe.directory pour pallier les problèmes éventuels d'ownership
        git config --global --get-all safe.directory | grep -qxF "$aodir" ||
            git config --global --add safe.directory "$aodir"

        # cloner ou mettre à jour
        origUpdateAo="$UpdateAo"
        if [ ! -d "$aodir" ]; then
            # Il faut cloner le dépôt
            qstep "clone $aourl --> $aodir"
            quietc git clone "$aourl" "$aodir" || continue
            # si une branche ou un commit sont spécifiés, forcer une mise à jour
            [ -n "$branch" -o -n "$commit" ] && UpdateAo=1
        fi

        if [ -n "$UpdateAo" ]; then
            # il faut mettre à jour le dépôt
            qstep "update $aodir${branch:+#$branch}${commit:+^$commit}"
            (
                cd "$aodir"
                quietc git fetch || exit 1
                if [ -n "$commit" ]; then
                    quietc git reset --hard "$commit"
                else
                    quietc git reset --hard "origin/${branch:-master}"
                fi
            )
        fi
        UpdateAo="$origUpdateAo"
    done

    if [ -n "$SelectAo" ]; then
        if [ ! -d "$AODIR/$SelectAo" -a -d "$AODIR/dreaddon-$SelectAo" ]; then
            array_del aonames "$SelectAo"
            SelectAo="dreaddon-$SelectAo"
            aonames+=("$SelectAo")
        elif [ ! -d "$APPDIR/$SelectAo" -a -d "$APPDIR/dreaddon-$SelectAo" ]; then
            array_del aonames "$SelectAo"
            SelectAo="dreaddon-$SelectAo"
            aonames+=("$SelectAo")
        elif [ ! -d "$AODIR/$SelectAo" -a ! -d "$APPDIR/$SelectAo" ]; then
            ewarn "$SelectAo: addon non installé"
        fi
    fi

    ADDONS=()
    for aoname in dreaddon-local "${aonames[@]}"; do
        [ -z "$SelectAo" -o "$aoname" == "$SelectAo" ] || continue
        if [ "${aoname#dreaddon-}" != "$aoname" -a -d "$APPDIR/$aoname" ]; then
            aodir="$APPDIR/$aoname"
        elif [ -d "$AODIR/$aoname" ]; then
            aodir="$AODIR/$aoname"
        else
            eerror "$aoname: addon introuvable"
            continue
        fi

        if [ ! -f "$aodir/dreaddon.conf" ]; then
            ewarn "$aodir: n'est pas un répertoire d'addons"
            continue
        fi

        # calculer la version minimum
        minv=
        setx -a vs=ls_dirs "$aodir" "v*"
        if [ ${#vs[*]} -eq 0 -a -d "$aodir/documentation" ]; then
            setx -a vs=ls_dirs "$aodir/documentation" "v*"
        fi
        for v in "${vs[@]}"; do
            v="${v#v}"
            [ -z "${v//[0-9]/}" ] || continue
            if [ -z "$minv" ]; then minv="$v"
            elif [ $v -lt $minv ]; then minv="$v"
            fi
        done

        eval "$(SCHEMAS=(); COMPAT=; source "$aodir/dreaddon.conf"; echo "DROP_SCHEMA_SCHEMAS+=(${SCHEMAS[*]}); vxx=${COMPAT:-all}")"
        if [ "$vxx" == all ]; then
            vxx=
        else
            [ "$vxx" == vxx ] && vxx="v$majeure"
            if [ ! -d "$aodir/$vxx" -a ! -d "$aodir/documentation/$vxx" ]; then
                v="${vxx#v}"
                found=
                if [ -n "$minv" ]; then
                    while [ $v -gt $minv ]; do
                        let v=v-1
                        if [ -d "$aodir/v$v" ]; then
                            found=1
                            vxx="v$v"
                            enote "$aoname: Sélection de la version $vxx au lieu de v$majeure"
                            break
                        fi
                    done
                fi
                if [ -z "$found" ]; then
                    ewarn "$aodir: cet addon est incompatible avec la version $vxx, il sera ignoré"
                    continue
                fi
            fi
            vxx=":$vxx"
        fi
        ADDONS+=("$aodir$vxx")
    done
fi

if [ -n "$step_import" ]; then
    if [ -n "$MinimizeDowntime" ]; then
        finaldb="$PGDATABASE"
        PGDATABASE=

        etitle "Nettoyage des bases de données temporaires"
        setx -a tmpdbs=psql -t --csv -c "\
select datname from pg_database where datname like 'dre_tmp%' or datname like 'dre_delete%';
"
        for tmpdb in "${tmpdbs[@]}"; do
            estep "$tmpdb"
            runsql "\
drop database if exists $tmpdb with (force);
" || critical
        done
        eend

        tmpdb="dre_tmp$$"
        moridb="dre_delete$$"
        etitle "Création de la base de données temporaire $tmpdb"
        runsql "\
create database $tmpdb;
" || critical
        PGDATABASE="$tmpdb"
        runsql "$(pg_grant_default_privileges)" || critical
        if [ -n "$PDBNAME" ]; then
            qstep "configuration $PDBNAME"
            quietc setup-pdb.sh
        fi
    else
        etitle "Suppression des anciens schémas"
        schema_list=
        for schema in "${DROP_SCHEMA_SCHEMAS[@]}" "${DROP_MONGO_SCHEMAS[@]}"; do
            qstep "$schema"
            schema_list="${schema_list}${schema_list:+, }${schema}"
        done
        runsql "\
drop schema if exists $schema_list cascade;
" || critical
        eend
    fi
fi

if [ -n "$step_import_bin" ]; then
    etitle "Importation des schémas (pgsql)"
    for schema in "${VxxFIX_FC[@]}"; do
        schema="schema_${schema#schema_}"
        qstep "$schema: create schema"
        runsql "\
create schema if not exists $schema;
" || critical
    done

    for schema in "${IMPORT_SCHEMA_SCHEMAS[@]}"; do
        file="${DRE_PREFIX}-$Timestamp-$schema.bin"
        schema="schema_$schema"

        qstep "$schema: drop extensions"
        runsql "\
drop extension if exists unaccent, pg_trgm cascade;
" || critical

        qstep "$schema: import $file"
        quietc pg_restore -d "$PGDATABASE" --no-owner --no-acl -Fc <"$file" || critical
        runsql "$(pg_grant_schema_privileges "$schema")" || critical
    done
    eend
fi

if [ -n "$step_import_json" ]; then
    etitle "Création des schémas (json)"
    for schema in "${IMPORT_MONGO_SCHEMAS[@]}"; do
        schema="mongo_$schema"

        qstep "$schema"
        runsql "\
create schema if not exists $schema;
" || critical
    done
    eend

    etitle "Importation des collections (json)"
    function cat_json() {
        local file="$1"
        case "$file" in
        *.json) cat "$file";;
        *.json.gz) gzip -dc "$file";;
        esac
    }
    function import_json() {
        local schema="$1" collection="$2" file="$3"
        [ -f "$file.gz" ] && file="$file.gz"

        qstep "$schema: $collection: import $file"
        runsql "
create table if not exists $schema.$collection (source_json jsonb);
" || critical
        cat_json "$file" | runsql "
copy $schema.$collection(source_json) from stdin csv quote e'\\x01' delimiter e'\\x02';
" || critical
    }
    import_json mongo_piste_inscription version_instance "$version"
    for schema_collection in "${IMPORT_MONGO_COLLECTIONS[@]}"; do
        splitpair "$schema_collection" schema collection
        file="${DRE_PREFIX}-$Timestamp-$schema-$collection.json"
        schema="mongo_$schema"
        import_json "$schema" "$collection" "$file"
    done
    for schema in "${IMPORT_MONGO_SCHEMAS[@]}"; do
        schema="mongo_$schema"

        qstep "$schema: maj authnz"
        runsql "$(pg_grant_schema_privileges "$schema")" || critical
    done
    eend
fi

if [ -n "$step_runao" ]; then
    etitle "Installation des addons"
    mkdir -p "$WORKDIR"

    have_ignore_errors=
    for addon in "${ADDONS[@]}"; do
        etitle "$addon"; quietc_echo "** install $addon"
        if [[ "$addon" == *:* ]]; then
            aodir="${addon%:*}"
            vxx="${addon##*:}"
        else
            aodir="$addon"
            vxx=
        fi
        SCHEMAS=()
        eval "$(SCHEMAS=(); IGNORE_ERRORS=; source "$aodir/dreaddon.conf"; echo "SCHEMAS+=(${SCHEMAS[*]}); IGNORE_ERRORS=$IGNORE_ERRORS")"
        runsql_ignore_errors "$IGNORE_ERRORS"
        [ -n "$IGNORE_ERRORS" ] && have_ignore_errors=1
        errors=

        if [ -d "$aodir/prepare" ]; then
            estep "Préparation"
            # Les scripts de préparation peuvent créer les schémas nécessaires ou
            # faire toute autre opération utile
            rundir "$aodir/prepare" || errors=1
        fi
        if [ -z "$errors" ]; then
            # S'assurer tout de même que les schémas mentionnés existent
            for schema in "${SCHEMAS[@]}"; do
                qstep "$schema: create schema"
                runsql "create schema if not exists $schema;" || errors=1
            done
        fi

        have_vxx=
        if [ -z "$errors" -a -n "$vxx" -a -d "$aodir/$vxx" ]; then
            have_vxx=1
            rundir "$aodir/$vxx" || errors=1
        fi

        if [ -z "$errors" -a -d "$aodir/updates" ]; then
            [ -z "$have_vxx" ] && estep "Mises à jour"
            rundir "$aodir/updates" || errors=1
        fi
        if [ -z "$errors" ]; then
            # Donner un accès complet en lecture aux comptes
            for schema in "${SCHEMAS[@]}"; do
                qstep "$schema: maj authnz"
                runsql "$(pg_grant_schema_privileges "$schema")" || errors=1
            done
        fi

        if [ -d "$aodir/documentation" ]; then
            estep "Documentation générale"
            rsync -dl --copy-unsafe-links "$aodir/documentation/" "$WORKDIR/documentation/"
        fi
        if [ -d "$aodir/documentation/$vxx" ]; then
            estep "Documentation $vxx"
            rsync -rl --copy-unsafe-links "$aodir/documentation/$vxx/" "$WORKDIR/documentation/"
        fi

        if [ -n "$errors" ]; then
            eimportant "Des erreurs se sont produites. l'installation de cet addon est incomplète"
            HAVE_ERRORS=1
        fi
        eend
    done

    [ -d "$WORKDIR/documentation" ] && estep "Installation de la documentation"
    # créer à vide si nécessaire, pour que la synchro efface les fichiers obsolètes
    mkdir -p "$WORKDIR/documentation"
    rsync -rl --delete "$WORKDIR/documentation/" "$DOCDIR/"

    rm -rf "$WORKDIR"

    if [ -n "$have_ignore_errors" ] && grep -q "ERROR:" "$APP_DATADIR/import.log"; then
        eimportant "Des erreurs se sont produites pendant l'import. Veuillez consulter les logs"
    fi

    eend
fi

if [ -n "$step_import_bin" ]; then
    estep "Maj version"
    profile="${APP_PROFILE^^}"
    lprofile="$APP_PROFILE"
    <"$version" runsql "\
create table if not exists version (
  majeure varchar
, mineure varchar
, patch varchar
, prerelease varchar
, timestamp varchar
, profile varchar
, source_json jsonb
);
truncate table version;
copy version(source_json) from stdin csv quote e'\\x01' delimiter e'\\x02';
update version set
  majeure = source_json->>'majeure'
, mineure = source_json->>'mineure'
, patch = source_json->>'patch'
, prerelease = source_json->>'prerelease'
, timestamp = '$Timestamp'
, profile = '$lprofile'
;

create table if not exists \"_infos_$profile\" (description varchar);
truncate table \"_infos_$profile\";
insert into \"_infos_$profile\" (description) values
('Cette base de données est sur l''instance du profil $profile')
;
" || critical
fi

if [ -n "$step_import" -a -n "$MinimizeDowntime" ]; then
    estep "Bascule $tmpdb --> $finaldb"
    runsql "select pg_terminate_backend(pid) from pg_stat_activity where datname = '$finaldb';"
    runsql "alter database $finaldb rename to $moridb;"
    PGDATABASE= runsql "alter database $tmpdb rename to $finaldb;"
    PGDATABASE="$finaldb"
    runsql "drop database if exists $moridb;"
    eend
fi

setx DATE_FIN=date +"%F %T"; export DATE_FIN
if [ -n "$step_import" ]; then
    qstep "Fin de l'import le $DATE_FIN"
fi
